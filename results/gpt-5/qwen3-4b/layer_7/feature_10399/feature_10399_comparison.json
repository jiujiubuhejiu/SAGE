{
  "configuration": {
    "model_name": "qwen3-4b",
    "sae_path": null,
    "layer": "7-transcoder-hp",
    "feature_index": 10399,
    "llm_model": "gpt-5",
    "num_examples": 10,
    "activation_threshold_original": 8.0,
    "activation_threshold_used": 1.7328,
    "activation_threshold_source": "dynamic_from_api_exemplars",
    "evaluation_method": "neuronpedia_api",
    "generation_evaluation_uses_api": true,
    "prediction_evaluation_uses_api": true,
    "prediction_evaluation_uses_exemplars": true,
    "prediction_evaluation_uses_selected_exemplars": true,
    "prediction_evaluation_activations_from_exemplars": true,
    "prediction_evaluation_uses_global_normalization": true,
    "global_max_activation": 4.031,
    "neuronpedia_model_id": "qwen3-4b",
    "token_usage": {
      "gpt5": {
        "prompt_tokens": 853,
        "completion_tokens": 4664,
        "total_tokens": 5517,
        "cost_input": 0.000533125,
        "cost_output": 0.02332,
        "cost_total": 0.023853125
      },
      "gpt4o": {
        "prompt_tokens": 41670,
        "completion_tokens": 212,
        "total_tokens": 41882,
        "cost_input": 0.0520875,
        "cost_output": 0.00106,
        "cost_total": 0.0531475
      },
      "total": {
        "prompt_tokens": 42523,
        "completion_tokens": 4876,
        "total_tokens": 47399,
        "cost_input": 0.052620625000000004,
        "cost_output": 0.02438,
        "cost_total": 0.077000625
      },
      "pricing": {
        "gpt5": {
          "input_per_1m": 0.625,
          "cached_input_per_1m": 0.0625,
          "output_per_1m": 5.0
        },
        "gpt4o": {
          "input_per_1m": 1.25,
          "output_per_1m": 5.0
        }
      }
    },
    "threshold_calculation": {
      "exemplars_used": 10,
      "max_activations": [
        4.031,
        4.031,
        4.031,
        4.031,
        3.578,
        3.578,
        2.891,
        2.891,
        2.797,
        2.797
      ],
      "average_max_activation": 1.7328,
      "min_max_activation": 2.797,
      "max_max_activation": 4.031
    },
    "prediction_evaluation_selection": {
      "total_exemplars": 42,
      "excluded_top_n": 10,
      "selected_count": 10,
      "selection_distribution": {
        "num_high": 4,
        "num_medium": 3,
        "num_low": 3
      },
      "selected_texts": [
        " is long-term\n\nA total Guide to Intercourse",
        " Customer Service to ensure your total satisfaction. Our commitment to",
        " condemned two oil contracts between TotalElf",
        " well,\" he said regarding Total Divas. He indicated",
        "sthodontics procedure for total rehabilitation of the edent",
        " when a cancer occurs. Total laryngectomy upset",
        "ally invasive techniques. A total of 94 patients",
        "user\nconfig BTRFS",
        " is especially useful in a total mixed ration mixing machine.",
        "user\nSounds stadium financing unclear"
      ],
      "selected_activations": [
        2.516,
        2.641,
        2.484,
        2.75,
        2.406,
        2.203,
        2.031,
        0.0,
        1.273,
        0.0
      ],
      "activation_range": [
        0.0,
        2.75
      ]
    },
    "note": "All activation evaluations use Neuronpedia API. Activation threshold is dynamically calculated from top 10 high-activating API exemplars (average of max activations / 2). Generation Evaluation uses top 10 high-activating exemplars. Prediction Evaluation uses selected exemplars directly from API (excluding top 10), with activation values already available (no API calls needed for activations). model_name and sae_path are kept for record-keeping only and are not used for any calculations."
  },
  "saia": {
    "explanation": {
      "description": "Feature 10399 detects the English lexeme “total” as a standalone token, with a strong preference for lowercase ' total' in prenominal adjective and subject-NP contexts. Activation is context-sensitive: strong for “the total [is/was] …” and “a/your total [N]” (≈1.16–1.59), weak for adverbial “In total” (≈0.09), and often zero in object-NP and predicative-adjective uses; titlecase ' Total' in proper names is usually zero with occasional weak activation. Across 16 tests, ' total' ranged 0.0000–1.5859 (7/11 strong >1.0, 1/11 weak ≈0.09, 3/11 zero), while morphological/subtoken variants (totally, totality, totals, totaled) were 0.0000 and ' subtotal' showed only weak spillover (0.3145).",
      "evidence": "- Test 1: \"The total is five.\" → ' total'=1.4688 (supports H1)\n- Test 2: \"The total cost was high.\" → ' total'=1.4688 (supports H1)\n- Test 4: \"The total cost exceeded the Total Divas budget.\" → ' total'=1.4688; ' Total'=0.0000 (supports H1, H4)\n- Test 5: \"In total, we spent ten dollars.\" → ' total'=0.0923 (supports H1: weak adverbial)\n- Test 6: \"The cost was total.\" → ' total'=0.0000 (supports H2 refutation; aligns with H1 context-sensitivity)\n- Test 7: \"The subtotal was correct.\" → ' subtotal'=0.3145 (supports H3: weak spillover)\n- Test 8: \"Your total satisfaction matters more than Total War sales.\" → ' total'=1.5859; ' Total'=0.3320 (supports H1, H4)\n- Test 9: \"We calculated the total today.\" → ' total'=0.0000 (supports H1: object NP often zero)\n- Test 10: \"A total disaster.\" → ' total'=1.1562 (supports H1)\n- Test 11: \"We paid the total.\" → ' total'=0.0000 (supports H1: object NP often zero)\n- Test 12: \"The total was ten.\" → ' total'=1.4688 (supports H1)\n- Test 13: \"The totality was ignored.\" → 0.0000 (supports H3)\n- Test 14: \"Totals are listed here.\" → 0.0000 (supports H3)\n- Test 15: \"They totaled the car.\" → 0.0000 (supports H3)\n- Test 16: \"The total budget beat Total 911.\" → ' total'=1.4688; ' Total'=0.0000 (supports H1, H4)",
      "labels": [
        {
          "number": 1,
          "text": "Lowercase “total” detector (prenominal/subject-NP contexts); suppressed for adverbial/predicative/object uses; insensitive to morphological variants and mostly to titlecase “Total” in proper nouns"
        }
      ],
      "label1": "Lowercase “total” detector (prenominal/subject-NP contexts); suppressed for adverbial/predicative/object uses; insensitive to morphological variants and mostly to titlecase “Total” in proper nouns",
      "label2": ""
    },
    "generated_examples": [
      "The total is 57 dollars after tax.",
      "The total was higher than we expected.",
      "The total is due today.",
      "Your total score is displayed at the top.",
      "Their total revenue was reported yesterday.",
      "Our total balance is now zero.",
      "A total eclipse was visible across the city.",
      "The total is on page three of the report.",
      "My total bandwidth is limited during peak hours.",
      "The total is exactly what we budgeted."
    ],
    "generation_evaluation": {
      "metrics": {
        "total_examples": 10,
        "successful_examples": 0,
        "success_rate": 0.0,
        "avg_max_activation_all": 1.321875,
        "avg_mean_activation_all": 0.14285378900613277,
        "avg_max_activation_successful": 0.0,
        "avg_mean_activation_successful": 0.0
      },
      "detailed_results": [
        {
          "example": "The total is 57 dollars after tax.",
          "max_activation": 1.46875,
          "mean_activation": 0.13352272727272727,
          "success": false,
          "max_token": " total",
          "max_token_idx": 2,
          "tokens": [
            "<|im_end|>",
            "The",
            " total",
            " is",
            " ",
            "5",
            "7",
            " dollars",
            " after",
            " tax",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            1.46875,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "The total was higher than we expected.",
          "max_activation": 1.46875,
          "mean_activation": 0.16319444444444445,
          "success": false,
          "max_token": " total",
          "max_token_idx": 2,
          "tokens": [
            "<|im_end|>",
            "The",
            " total",
            " was",
            " higher",
            " than",
            " we",
            " expected",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            1.46875,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "The total is due today.",
          "max_activation": 1.46875,
          "mean_activation": 0.20982142857142858,
          "success": false,
          "max_token": " total",
          "max_token_idx": 2,
          "tokens": [
            "<|im_end|>",
            "The",
            " total",
            " is",
            " due",
            " today",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            1.46875,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "Your total score is displayed at the top.",
          "max_activation": 1.5859375,
          "mean_activation": 0.15859375,
          "success": false,
          "max_token": " total",
          "max_token_idx": 2,
          "tokens": [
            "<|im_end|>",
            "Your",
            " total",
            " score",
            " is",
            " displayed",
            " at",
            " the",
            " top",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            1.5859375,
            0,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "Their total revenue was reported yesterday.",
          "max_activation": 0.7734375,
          "mean_activation": 0.0966796875,
          "success": false,
          "max_token": " total",
          "max_token_idx": 2,
          "tokens": [
            "<|im_end|>",
            "Their",
            " total",
            " revenue",
            " was",
            " reported",
            " yesterday",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0.7734375,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "Our total balance is now zero.",
          "max_activation": 1.390625,
          "mean_activation": 0.173828125,
          "success": false,
          "max_token": " total",
          "max_token_idx": 2,
          "tokens": [
            "<|im_end|>",
            "Our",
            " total",
            " balance",
            " is",
            " now",
            " zero",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            1.390625,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "A total eclipse was visible across the city.",
          "max_activation": 1.15625,
          "mean_activation": 0.115625,
          "success": false,
          "max_token": " total",
          "max_token_idx": 2,
          "tokens": [
            "<|im_end|>",
            "A",
            " total",
            " eclipse",
            " was",
            " visible",
            " across",
            " the",
            " city",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            1.15625,
            0,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "The total is on page three of the report.",
          "max_activation": 1.46875,
          "mean_activation": 0.13352272727272727,
          "success": false,
          "max_token": " total",
          "max_token_idx": 2,
          "tokens": [
            "<|im_end|>",
            "The",
            " total",
            " is",
            " on",
            " page",
            " three",
            " of",
            " the",
            " report",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            1.46875,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "My total bandwidth is limited during peak hours.",
          "max_activation": 0.96875,
          "mean_activation": 0.096875,
          "success": false,
          "max_token": " total",
          "max_token_idx": 2,
          "tokens": [
            "<|im_end|>",
            "My",
            " total",
            " bandwidth",
            " is",
            " limited",
            " during",
            " peak",
            " hours",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0.96875,
            0,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "The total is exactly what we budgeted.",
          "max_activation": 1.46875,
          "mean_activation": 0.146875,
          "success": false,
          "max_token": " total",
          "max_token_idx": 2,
          "tokens": [
            "<|im_end|>",
            "The",
            " total",
            " is",
            " exactly",
            " what",
            " we",
            " budget",
            "ed",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            1.46875,
            0,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        }
      ]
    },
    "prediction_evaluation": {
      "correlation": -0.04704818867892303,
      "p_value": 0.6320007282225268,
      "predictions": [
        2.913215579782851e-05,
        0.6517767999886015,
        0.0003627517896354625,
        0.0007102092555837143,
        0.0005433685631912919,
        0.00030086575472866654,
        0.6959792932951807,
        0.8895433631917605,
        0.005528911486160305,
        2.2930908955035676,
        0.27300059211808964,
        0.2184725186718751,
        4.462695376605504e-05,
        0.00030461713081403937,
        3.686161951555772e-05,
        1.1945229785971094e-05,
        3.997165371777615e-06,
        0.00011551278477696638,
        0.08493579645340339,
        7.995923866106569,
        6.810666834812892,
        0.12629395970656335,
        0.7162362790624639,
        0.10653647402710574,
        7.283785993876262e-06,
        1.0154086986889095e-05,
        2.8537815426997282e-05,
        1.837144725008005e-05,
        1.4125718897087189e-05,
        1.1359978358495886e-05,
        2.413681285659806e-05,
        4.236726137318218e-05,
        1.7375253818402337e-05,
        1.9187941032289216e-05,
        6.3009494038476765e-06,
        1.1049539689123686e-05,
        1.4676608451274944e-05,
        1.4449434979757856e-05,
        1.088427128882142,
        0.00026841675375360684,
        0.0001359008292808733,
        0.0006137875988485019,
        3.895275840747153e-05,
        3.0332129442760788e-05,
        1.7375253818402337e-05,
        8.642870407558327e-06,
        1.3275305763794635e-05,
        1.8992789377778116e-05,
        3.2223385940995816e-05,
        4.3849547112360834e-05,
        0.6661683509613582,
        0.6750884315470153,
        0.0008630442135679407,
        0.007235512543051914,
        0.0004628161821481282,
        0.0018179228207725264,
        7.481850259560639e-06,
        1.0280534777101037e-05,
        0.0008370618509696695,
        1.591158362950729e-05,
        1.7412100565017087e-05,
        7.493673406449585e-05,
        8.069310080839011e-05,
        0.00012278506838125114,
        6.091043638092602e-05,
        7.55736325418833e-05,
        0.0006357190114638282,
        1.4965532598130009e-05,
        3.831642337344506e-05,
        3.0658180420294295e-05,
        8.237777685377107e-06,
        3.911570649827251e-05,
        1.700271504329694e-05,
        7.561334578391684e-05,
        0.008640427324111926,
        1.4745533207727277,
        6.0634105003481,
        9.413021151100155,
        7.241425986102369,
        5.781796604694112,
        2.0183055274206852e-05,
        5.0381119225439814e-06,
        0.3679106359795238,
        1.029335333489827e-05,
        0.00028472479801898545,
        0.00016326945903489753,
        0.022886645886589264,
        2.0183055274206852e-05,
        0.1699981865064994,
        0.00015995937678384926,
        2.839700622334496e-05,
        2.6686984818365876e-05,
        0.00016933112997853008,
        0.3561144927997557,
        2.9922205859073476,
        7.460990513379547,
        0.555466674709617,
        3.004872089196602,
        7.029503205265082,
        2.4619406593116752e-05,
        1.44387579311632e-05,
        0.2654683346857052,
        2.237168929234724e-05,
        2.017623711665727e-05,
        6.07747525724597e-05,
        0.0002706391049506776
      ],
      "true_values": [
        0.0,
        0.22409335462664354,
        0.0,
        0.0,
        0.0,
        0.0,
        5.349168940709502,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        4.205687174398412,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        5.039072190523443,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        5.698027784668818,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        5.620503597122303,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        4.360735549491442,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        5.039072190523443,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.22409335462664354,
        0.0,
        0.0,
        0.0,
        0.0,
        6.240697097494419,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "num_tokens": 106,
      "num_examples": 10,
      "example_results": [
        {
          "text": " is long-term\n\nA total Guide to Intercourse",
          "tokens": [
            "<|im_end|>",
            " is",
            " long",
            "-term",
            "\n\n",
            "A",
            " total",
            " Guide",
            " to",
            " Int",
            "erc",
            "ourse"
          ],
          "predicted_values": [
            2.913215579782851e-05,
            0.6517767999886015,
            0.0003627517896354625,
            0.0007102092555837143,
            0.0005433685631912919,
            0.00030086575472866654,
            0.6959792932951807,
            0.8895433631917605,
            0.005528911486160305,
            2.2930908955035676,
            0.27300059211808964,
            0.2184725186718751
          ],
          "actual_values": [
            0.0,
            0.22409335462664354,
            0.0,
            0.0,
            0.0,
            0.0,
            5.349168940709502,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": " Customer Service to ensure your total satisfaction. Our commitment to",
          "tokens": [
            "<|im_end|>",
            " Customer",
            " Service",
            " to",
            " ensure",
            " your",
            " total",
            " satisfaction",
            ".",
            " Our",
            " commitment",
            " to"
          ],
          "predicted_values": [
            4.462695376605504e-05,
            0.00030461713081403937,
            3.686161951555772e-05,
            1.1945229785971094e-05,
            3.997165371777615e-06,
            0.00011551278477696638,
            0.08493579645340339,
            7.995923866106569,
            6.810666834812892,
            0.12629395970656335,
            0.7162362790624639,
            0.10653647402710574
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            4.205687174398412,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": " condemned two oil contracts between TotalElf",
          "tokens": [
            "<|im_end|>",
            " condemned",
            " two",
            " oil",
            " contracts",
            " between",
            " Total",
            "Elf"
          ],
          "predicted_values": [
            7.283785993876262e-06,
            1.0154086986889095e-05,
            2.8537815426997282e-05,
            1.837144725008005e-05,
            1.4125718897087189e-05,
            1.1359978358495886e-05,
            2.413681285659806e-05,
            4.236726137318218e-05
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            5.039072190523443,
            0.0
          ],
          "num_tokens": 8
        },
        {
          "text": " well,\" he said regarding Total Divas. He indicated",
          "tokens": [
            "<|im_end|>",
            " well",
            ",\"",
            " he",
            " said",
            " regarding",
            " Total",
            " Div",
            "as",
            ".",
            " He",
            " indicated"
          ],
          "predicted_values": [
            1.7375253818402337e-05,
            1.9187941032289216e-05,
            6.3009494038476765e-06,
            1.1049539689123686e-05,
            1.4676608451274944e-05,
            1.4449434979757856e-05,
            1.088427128882142,
            0.00026841675375360684,
            0.0001359008292808733,
            0.0006137875988485019,
            3.895275840747153e-05,
            3.0332129442760788e-05
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            5.698027784668818,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": "sthodontics procedure for total rehabilitation of the edent",
          "tokens": [
            "<|im_end|>",
            "sth",
            "odont",
            "ics",
            " procedure",
            " for",
            " total",
            " rehabilitation",
            " of",
            " the",
            " ed",
            "ent"
          ],
          "predicted_values": [
            1.7375253818402337e-05,
            8.642870407558327e-06,
            1.3275305763794635e-05,
            1.8992789377778116e-05,
            3.2223385940995816e-05,
            4.3849547112360834e-05,
            0.6661683509613582,
            0.6750884315470153,
            0.0008630442135679407,
            0.007235512543051914,
            0.0004628161821481282,
            0.0018179228207725264
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            5.620503597122303,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": " when a cancer occurs. Total laryngectomy upset",
          "tokens": [
            "<|im_end|>",
            " when",
            " a",
            " cancer",
            " occurs",
            ".",
            " Total",
            " l",
            "ary",
            "ng",
            "ectomy",
            " upset"
          ],
          "predicted_values": [
            7.481850259560639e-06,
            1.0280534777101037e-05,
            0.0008370618509696695,
            1.591158362950729e-05,
            1.7412100565017087e-05,
            7.493673406449585e-05,
            8.069310080839011e-05,
            0.00012278506838125114,
            6.091043638092602e-05,
            7.55736325418833e-05,
            0.0006357190114638282,
            1.4965532598130009e-05
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            4.360735549491442,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": "ally invasive techniques. A total of 94 patients",
          "tokens": [
            "<|im_end|>",
            "ally",
            " invasive",
            " techniques",
            ".",
            " A",
            " total",
            " of",
            " ",
            "9",
            "4",
            " patients"
          ],
          "predicted_values": [
            3.831642337344506e-05,
            3.0658180420294295e-05,
            8.237777685377107e-06,
            3.911570649827251e-05,
            1.700271504329694e-05,
            7.561334578391684e-05,
            0.008640427324111926,
            1.4745533207727277,
            6.0634105003481,
            9.413021151100155,
            7.241425986102369,
            5.781796604694112
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            5.039072190523443,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": "user\nconfig BTRFS",
          "tokens": [
            "<|im_end|>",
            "user",
            "\n",
            "config",
            " B",
            "TR",
            "FS"
          ],
          "predicted_values": [
            2.0183055274206852e-05,
            5.0381119225439814e-06,
            0.3679106359795238,
            1.029335333489827e-05,
            0.00028472479801898545,
            0.00016326945903489753,
            0.022886645886589264
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 7
        },
        {
          "text": " is especially useful in a total mixed ration mixing machine.",
          "tokens": [
            "<|im_end|>",
            " is",
            " especially",
            " useful",
            " in",
            " a",
            " total",
            " mixed",
            " ration",
            " mixing",
            " machine",
            "."
          ],
          "predicted_values": [
            2.0183055274206852e-05,
            0.1699981865064994,
            0.00015995937678384926,
            2.839700622334496e-05,
            2.6686984818365876e-05,
            0.00016933112997853008,
            0.3561144927997557,
            2.9922205859073476,
            7.460990513379547,
            0.555466674709617,
            3.004872089196602,
            7.029503205265082
          ],
          "actual_values": [
            0.0,
            0.22409335462664354,
            0.0,
            0.0,
            0.0,
            0.0,
            6.240697097494419,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": "user\nSounds stadium financing unclear",
          "tokens": [
            "<|im_end|>",
            "user",
            "\n",
            "Sounds",
            " stadium",
            " financing",
            " unclear"
          ],
          "predicted_values": [
            2.4619406593116752e-05,
            1.44387579311632e-05,
            0.2654683346857052,
            2.237168929234724e-05,
            2.017623711665727e-05,
            6.07747525724597e-05,
            0.0002706391049506776
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 7
        }
      ],
      "skipped": false,
      "correlation_valid": true,
      "prediction_variance": 3.805361570005534,
      "actual_variance": 1.9109794347271911,
      "method": "logprobs_token_level",
      "token_usage": {
        "prompt_tokens": 30269,
        "completion_tokens": 106,
        "total_tokens": 30375,
        "cost_input": 0.03783625,
        "cost_output": 0.00053,
        "cost_total": 0.038366250000000005
      },
      "activation_source": "neuronpedia_api",
      "api_config": {
        "model_id": "qwen3-4b",
        "layer": "7-transcoder-hp",
        "feature_index": 10399
      }
    }
  },
  "neuronpedia": {
    "explanation": {
      "description": "mentions of the quantifier meaning “entire/whole,” whether used as a common adjective or within proper names and titles.",
      "label1": "",
      "label2": ""
    },
    "raw_api_response": {
      "explanation": {
        "id": "cmi3o8jra002dpywn9xhon9vj",
        "modelId": "qwen3-4b",
        "layer": "7-transcoder-hp",
        "index": "10399",
        "description": "mentions of the quantifier meaning “entire/whole,” whether used as a common adjective or within proper names and titles.",
        "authorId": "cmgfd4ew3004cnf0ds8gk5ogz",
        "triggeredByUserId": "cmgfd4ew3004cnf0ds8gk5ogz",
        "notes": null,
        "scoreV1": 0,
        "scoreV2": null,
        "umap_x": 0,
        "umap_y": 0,
        "umap_cluster": 0,
        "umap_log_feature_sparsity": 0,
        "typeName": "oai_token-act-pair",
        "explanationModelName": "gpt-5",
        "createdAt": "2025-11-17T21:43:20.298Z",
        "updatedAt": "2025-11-17T21:43:20.298Z"
      },
      "source": "new"
    },
    "explanation_source": "new",
    "explanation_id": "cmi3o8jra002dpywn9xhon9vj",
    "all_available_explanations": [],
    "generated_examples": [
      "I read the entire book overnight, cover to cover.",
      "She ate the whole cake herself during the party.",
      "The whole of France watched the final in silence.",
      "He spent the entire summer rebuilding the old boat.",
      "Please play the recording in its entirety for the committee.",
      "We watched The Entire History of You last night.",
      "They shivered through the whole night without a fire.",
      "She wants the whole truth, not a carefully edited summary.",
      "He bought The Whole Earth Catalog from a vintage shop.",
      "The board approved a whole-of-government response to disasters."
    ],
    "generation_evaluation": {
      "metrics": {
        "total_examples": 10,
        "successful_examples": 0,
        "success_rate": 0.0,
        "avg_max_activation_all": 0.0,
        "avg_mean_activation_all": 0.0,
        "avg_max_activation_successful": 0.0,
        "avg_mean_activation_successful": 0.0
      },
      "detailed_results": [
        {
          "example": "I read the entire book overnight, cover to cover.",
          "max_activation": 0,
          "mean_activation": 0.0,
          "success": false,
          "max_token": "<|im_end|>",
          "max_token_idx": 0,
          "tokens": [
            "<|im_end|>",
            "I",
            " read",
            " the",
            " entire",
            " book",
            " overnight",
            ",",
            " cover",
            " to",
            " cover",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "She ate the whole cake herself during the party.",
          "max_activation": 0,
          "mean_activation": 0.0,
          "success": false,
          "max_token": "<|im_end|>",
          "max_token_idx": 0,
          "tokens": [
            "<|im_end|>",
            "She",
            " ate",
            " the",
            " whole",
            " cake",
            " herself",
            " during",
            " the",
            " party",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "The whole of France watched the final in silence.",
          "max_activation": 0,
          "mean_activation": 0.0,
          "success": false,
          "max_token": "<|im_end|>",
          "max_token_idx": 0,
          "tokens": [
            "<|im_end|>",
            "The",
            " whole",
            " of",
            " France",
            " watched",
            " the",
            " final",
            " in",
            " silence",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "He spent the entire summer rebuilding the old boat.",
          "max_activation": 0,
          "mean_activation": 0.0,
          "success": false,
          "max_token": "<|im_end|>",
          "max_token_idx": 0,
          "tokens": [
            "<|im_end|>",
            "He",
            " spent",
            " the",
            " entire",
            " summer",
            " rebuilding",
            " the",
            " old",
            " boat",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "Please play the recording in its entirety for the committee.",
          "max_activation": 0,
          "mean_activation": 0.0,
          "success": false,
          "max_token": "<|im_end|>",
          "max_token_idx": 0,
          "tokens": [
            "<|im_end|>",
            "Please",
            " play",
            " the",
            " recording",
            " in",
            " its",
            " entirety",
            " for",
            " the",
            " committee",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "We watched The Entire History of You last night.",
          "max_activation": 0,
          "mean_activation": 0.0,
          "success": false,
          "max_token": "<|im_end|>",
          "max_token_idx": 0,
          "tokens": [
            "<|im_end|>",
            "We",
            " watched",
            " The",
            " Entire",
            " History",
            " of",
            " You",
            " last",
            " night",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "They shivered through the whole night without a fire.",
          "max_activation": 0,
          "mean_activation": 0.0,
          "success": false,
          "max_token": "<|im_end|>",
          "max_token_idx": 0,
          "tokens": [
            "<|im_end|>",
            "They",
            " sh",
            "ivered",
            " through",
            " the",
            " whole",
            " night",
            " without",
            " a",
            " fire",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "She wants the whole truth, not a carefully edited summary.",
          "max_activation": 0,
          "mean_activation": 0.0,
          "success": false,
          "max_token": "<|im_end|>",
          "max_token_idx": 0,
          "tokens": [
            "<|im_end|>",
            "She",
            " wants",
            " the",
            " whole",
            " truth",
            ",",
            " not",
            " a",
            " carefully",
            " edited",
            " summary",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "He bought The Whole Earth Catalog from a vintage shop.",
          "max_activation": 0,
          "mean_activation": 0.0,
          "success": false,
          "max_token": "<|im_end|>",
          "max_token_idx": 0,
          "tokens": [
            "<|im_end|>",
            "He",
            " bought",
            " The",
            " Whole",
            " Earth",
            " Catalog",
            " from",
            " a",
            " vintage",
            " shop",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "The board approved a whole-of-government response to disasters.",
          "max_activation": 0,
          "mean_activation": 0.0,
          "success": false,
          "max_token": "<|im_end|>",
          "max_token_idx": 0,
          "tokens": [
            "<|im_end|>",
            "The",
            " board",
            " approved",
            " a",
            " whole",
            "-of",
            "-government",
            " response",
            " to",
            " disasters",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        }
      ]
    },
    "prediction_evaluation": {
      "correlation": 0.518576588407499,
      "p_value": 1.2393015641717521e-08,
      "predictions": [
        0.0009125355439847881,
        0.008026005079543897,
        0.06991058338273812,
        0.1995797186447447,
        0.027745016017651045,
        0.12278035772844524,
        9.702467124222508,
        4.932751572024374,
        8.758532399476325,
        7.035491716762022,
        7.8795255836905325,
        7.486703077107996,
        0.009851571414703997,
        0.01045350670203436,
        0.05425353067429289,
        0.007559045807329905,
        0.07578762373215936,
        0.0030355518601506656,
        9.47143505382585,
        9.29179731663576,
        8.34759051472777,
        0.021225993700665528,
        5.82127343162206,
        0.4295432372919202,
        0.0017745749109007048,
        0.01776872177347568,
        0.0011261629391397165,
        0.02671626130982633,
        0.002113966489666526,
        0.003188596570699682,
        9.840058106555162,
        1.872546483889424,
        0.003381386827861565,
        0.03426979171023974,
        0.0072930889257534805,
        0.0027130006037595993,
        0.001566684292733767,
        0.004012687425095271,
        9.924652758680505,
        8.872605402071269,
        4.804091369814826,
        7.36885808481627,
        0.736197274074911,
        6.429703393647813,
        0.009851571414703997,
        0.007264930155449446,
        0.01979127128206693,
        0.028365569583392772,
        0.04149734154891234,
        0.0011564750366263776,
        9.81099611691841,
        9.84089864892094,
        4.858956971146209,
        6.096299314214332,
        6.32132068532397,
        8.964737354978823,
        0.0018634109718583631,
        0.001871087672209553,
        0.027040384886521076,
        0.33876363117959135,
        0.021199301336137726,
        0.0037321856795604126,
        9.893251519938508,
        5.7830885472936355,
        7.378063896397628,
        2.4201242993905923,
        9.742115071070511,
        4.490454127730077,
        0.003381386827861565,
        0.18216301530231588,
        0.02582293745360512,
        0.004115916296264734,
        0.014490957022866723,
        0.13738432555832567,
        9.907746601484527,
        8.949798509627092,
        9.14034487335001,
        8.987467772884145,
        5.207810881028333,
        7.567693680855451,
        0.003381386827861565,
        0.0028192175948712397,
        0.4785660878363906,
        0.016947738420616115,
        0.01547775026132117,
        0.27945795487928926,
        0.26426193926037145,
        0.009756597019643777,
        0.011364298722057693,
        0.025494209764775552,
        0.019924376458530596,
        0.006329015359485535,
        0.04839412298393458,
        9.170767335406829,
        1.5173034862883017,
        3.3113859401809194,
        6.599016028461013,
        4.147337359844785,
        5.072245219271473,
        0.003381386827861565,
        0.002902916920869498,
        0.4116730729017579,
        0.022611767780633278,
        0.7982972527142679,
        0.336505773502199,
        0.8108261910659877
      ],
      "true_values": [
        0.0,
        0.22409335462664354,
        0.0,
        0.0,
        0.0,
        0.0,
        5.349168940709502,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        4.205687174398412,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        5.039072190523443,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        5.698027784668818,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        5.620503597122303,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        4.360735549491442,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        5.039072190523443,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.22409335462664354,
        0.0,
        0.0,
        0.0,
        0.0,
        6.240697097494419,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "num_tokens": 106,
      "num_examples": 10,
      "example_results": [
        {
          "text": " is long-term\n\nA total Guide to Intercourse",
          "tokens": [
            "<|im_end|>",
            " is",
            " long",
            "-term",
            "\n\n",
            "A",
            " total",
            " Guide",
            " to",
            " Int",
            "erc",
            "ourse"
          ],
          "predicted_values": [
            0.0009125355439847881,
            0.008026005079543897,
            0.06991058338273812,
            0.1995797186447447,
            0.027745016017651045,
            0.12278035772844524,
            9.702467124222508,
            4.932751572024374,
            8.758532399476325,
            7.035491716762022,
            7.8795255836905325,
            7.486703077107996
          ],
          "actual_values": [
            0.0,
            0.22409335462664354,
            0.0,
            0.0,
            0.0,
            0.0,
            5.349168940709502,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": " Customer Service to ensure your total satisfaction. Our commitment to",
          "tokens": [
            "<|im_end|>",
            " Customer",
            " Service",
            " to",
            " ensure",
            " your",
            " total",
            " satisfaction",
            ".",
            " Our",
            " commitment",
            " to"
          ],
          "predicted_values": [
            0.009851571414703997,
            0.01045350670203436,
            0.05425353067429289,
            0.007559045807329905,
            0.07578762373215936,
            0.0030355518601506656,
            9.47143505382585,
            9.29179731663576,
            8.34759051472777,
            0.021225993700665528,
            5.82127343162206,
            0.4295432372919202
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            4.205687174398412,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": " condemned two oil contracts between TotalElf",
          "tokens": [
            "<|im_end|>",
            " condemned",
            " two",
            " oil",
            " contracts",
            " between",
            " Total",
            "Elf"
          ],
          "predicted_values": [
            0.0017745749109007048,
            0.01776872177347568,
            0.0011261629391397165,
            0.02671626130982633,
            0.002113966489666526,
            0.003188596570699682,
            9.840058106555162,
            1.872546483889424
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            5.039072190523443,
            0.0
          ],
          "num_tokens": 8
        },
        {
          "text": " well,\" he said regarding Total Divas. He indicated",
          "tokens": [
            "<|im_end|>",
            " well",
            ",\"",
            " he",
            " said",
            " regarding",
            " Total",
            " Div",
            "as",
            ".",
            " He",
            " indicated"
          ],
          "predicted_values": [
            0.003381386827861565,
            0.03426979171023974,
            0.0072930889257534805,
            0.0027130006037595993,
            0.001566684292733767,
            0.004012687425095271,
            9.924652758680505,
            8.872605402071269,
            4.804091369814826,
            7.36885808481627,
            0.736197274074911,
            6.429703393647813
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            5.698027784668818,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": "sthodontics procedure for total rehabilitation of the edent",
          "tokens": [
            "<|im_end|>",
            "sth",
            "odont",
            "ics",
            " procedure",
            " for",
            " total",
            " rehabilitation",
            " of",
            " the",
            " ed",
            "ent"
          ],
          "predicted_values": [
            0.009851571414703997,
            0.007264930155449446,
            0.01979127128206693,
            0.028365569583392772,
            0.04149734154891234,
            0.0011564750366263776,
            9.81099611691841,
            9.84089864892094,
            4.858956971146209,
            6.096299314214332,
            6.32132068532397,
            8.964737354978823
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            5.620503597122303,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": " when a cancer occurs. Total laryngectomy upset",
          "tokens": [
            "<|im_end|>",
            " when",
            " a",
            " cancer",
            " occurs",
            ".",
            " Total",
            " l",
            "ary",
            "ng",
            "ectomy",
            " upset"
          ],
          "predicted_values": [
            0.0018634109718583631,
            0.001871087672209553,
            0.027040384886521076,
            0.33876363117959135,
            0.021199301336137726,
            0.0037321856795604126,
            9.893251519938508,
            5.7830885472936355,
            7.378063896397628,
            2.4201242993905923,
            9.742115071070511,
            4.490454127730077
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            4.360735549491442,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": "ally invasive techniques. A total of 94 patients",
          "tokens": [
            "<|im_end|>",
            "ally",
            " invasive",
            " techniques",
            ".",
            " A",
            " total",
            " of",
            " ",
            "9",
            "4",
            " patients"
          ],
          "predicted_values": [
            0.003381386827861565,
            0.18216301530231588,
            0.02582293745360512,
            0.004115916296264734,
            0.014490957022866723,
            0.13738432555832567,
            9.907746601484527,
            8.949798509627092,
            9.14034487335001,
            8.987467772884145,
            5.207810881028333,
            7.567693680855451
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            5.039072190523443,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": "user\nconfig BTRFS",
          "tokens": [
            "<|im_end|>",
            "user",
            "\n",
            "config",
            " B",
            "TR",
            "FS"
          ],
          "predicted_values": [
            0.003381386827861565,
            0.0028192175948712397,
            0.4785660878363906,
            0.016947738420616115,
            0.01547775026132117,
            0.27945795487928926,
            0.26426193926037145
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 7
        },
        {
          "text": " is especially useful in a total mixed ration mixing machine.",
          "tokens": [
            "<|im_end|>",
            " is",
            " especially",
            " useful",
            " in",
            " a",
            " total",
            " mixed",
            " ration",
            " mixing",
            " machine",
            "."
          ],
          "predicted_values": [
            0.009756597019643777,
            0.011364298722057693,
            0.025494209764775552,
            0.019924376458530596,
            0.006329015359485535,
            0.04839412298393458,
            9.170767335406829,
            1.5173034862883017,
            3.3113859401809194,
            6.599016028461013,
            4.147337359844785,
            5.072245219271473
          ],
          "actual_values": [
            0.0,
            0.22409335462664354,
            0.0,
            0.0,
            0.0,
            0.0,
            6.240697097494419,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": "user\nSounds stadium financing unclear",
          "tokens": [
            "<|im_end|>",
            "user",
            "\n",
            "Sounds",
            " stadium",
            " financing",
            " unclear"
          ],
          "predicted_values": [
            0.003381386827861565,
            0.002902916920869498,
            0.4116730729017579,
            0.022611767780633278,
            0.7982972527142679,
            0.336505773502199,
            0.8108261910659877
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 7
        }
      ],
      "skipped": false,
      "correlation_valid": true,
      "prediction_variance": 14.03789478300846,
      "actual_variance": 1.9109794347271911,
      "method": "logprobs_token_level",
      "token_usage": {
        "prompt_tokens": 11401,
        "completion_tokens": 106,
        "total_tokens": 11507,
        "cost_input": 0.01425125,
        "cost_output": 0.00053,
        "cost_total": 0.01478125
      },
      "activation_source": "neuronpedia_api",
      "api_config": {
        "model_id": "qwen3-4b",
        "layer": "7-transcoder-hp",
        "feature_index": 10399
      }
    }
  },
  "prediction_evaluation": {
    "selected_exemplars": [
      {
        "text": " is long-term\n\nA total Guide to Intercourse",
        "activation": 2.516
      },
      {
        "text": " Customer Service to ensure your total satisfaction. Our commitment to",
        "activation": 2.641
      },
      {
        "text": " condemned two oil contracts between TotalElf",
        "activation": 2.484
      },
      {
        "text": " well,\" he said regarding Total Divas. He indicated",
        "activation": 2.75
      },
      {
        "text": "sthodontics procedure for total rehabilitation of the edent",
        "activation": 2.406
      },
      {
        "text": " when a cancer occurs. Total laryngectomy upset",
        "activation": 2.203
      },
      {
        "text": "ally invasive techniques. A total of 94 patients",
        "activation": 2.031
      },
      {
        "text": "user\nconfig BTRFS",
        "activation": 0.0
      },
      {
        "text": " is especially useful in a total mixed ration mixing machine.",
        "activation": 1.273
      },
      {
        "text": "user\nSounds stadium financing unclear",
        "activation": 0.0
      }
    ],
    "selection_method": "random_selection_from_categorized_exemplars",
    "selection_details": {
      "excluded_top_n": 10,
      "num_high_selected": 4,
      "num_medium_selected": 3,
      "num_low_selected": 3,
      "total_selected": 10
    },
    "note": "Prediction Evaluation uses selected exemplars directly from API (excluding top 10 used for Generation Evaluation). Exemplars are categorized into high, medium, and low activation groups from remaining exemplars, and randomly selected from each group. Activation values are already available from exemplars, so no API calls are needed to get activations. This avoids bias from explanation text and ensures diverse activation levels in evaluation examples."
  },
  "comparison": {
    "generation": {
      "saia": {
        "total_examples": 10,
        "successful_examples": 0,
        "success_rate": 0.0,
        "avg_max_activation_all": 1.321875,
        "avg_mean_activation_all": 0.14285378900613277,
        "avg_max_activation_successful": 0.0,
        "avg_mean_activation_successful": 0.0
      },
      "neuronpedia": {
        "total_examples": 10,
        "successful_examples": 0,
        "success_rate": 0.0,
        "avg_max_activation_all": 0.0,
        "avg_mean_activation_all": 0.0,
        "avg_max_activation_successful": 0.0,
        "avg_mean_activation_successful": 0.0
      },
      "differences": {
        "success_rate_diff": 0.0,
        "avg_max_activation_diff": 1.321875,
        "avg_max_activation_successful_diff": 0.0
      },
      "winner": "TIE"
    },
    "prediction": {
      "saia": {
        "correlation": -0.04704818867892303,
        "p_value": 0.6320007282225268,
        "correlation_valid": true
      },
      "neuronpedia": {
        "correlation": 0.518576588407499,
        "p_value": 1.2393015641717521e-08,
        "correlation_valid": true
      },
      "difference": -0.565624777086422,
      "winner": "Neuronpedia"
    },
    "overall_winner": "Neuronpedia"
  }
}