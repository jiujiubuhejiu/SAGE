{
  "configuration": {
    "model_name": "qwen3-4b",
    "sae_path": null,
    "layer": "7-transcoder-hp",
    "feature_index": 10,
    "llm_model": "gpt-5",
    "num_examples": 10,
    "activation_threshold_original": 8.0,
    "activation_threshold_used": 1.56095,
    "activation_threshold_source": "dynamic_from_api_exemplars",
    "evaluation_method": "neuronpedia_api",
    "generation_evaluation_uses_api": true,
    "prediction_evaluation_uses_api": true,
    "prediction_evaluation_uses_exemplars": true,
    "prediction_evaluation_uses_selected_exemplars": true,
    "prediction_evaluation_activations_from_exemplars": true,
    "prediction_evaluation_uses_global_normalization": true,
    "global_max_activation": 3.906,
    "neuronpedia_model_id": "qwen3-4b",
    "token_usage": {
      "gpt5": {
        "prompt_tokens": 766,
        "completion_tokens": 3546,
        "total_tokens": 4312,
        "cost_input": 0.00047875,
        "cost_output": 0.01773,
        "cost_total": 0.018208750000000003
      },
      "gpt4o": {
        "prompt_tokens": 37879,
        "completion_tokens": 238,
        "total_tokens": 38117,
        "cost_input": 0.04734875,
        "cost_output": 0.00119,
        "cost_total": 0.04853875
      },
      "total": {
        "prompt_tokens": 38645,
        "completion_tokens": 3784,
        "total_tokens": 42429,
        "cost_input": 0.0478275,
        "cost_output": 0.01892,
        "cost_total": 0.0667475
      },
      "pricing": {
        "gpt5": {
          "input_per_1m": 0.625,
          "cached_input_per_1m": 0.0625,
          "output_per_1m": 5.0
        },
        "gpt4o": {
          "input_per_1m": 1.25,
          "output_per_1m": 5.0
        }
      }
    },
    "threshold_calculation": {
      "exemplars_used": 10,
      "max_activations": [
        3.906,
        3.906,
        3.672,
        3.672,
        2.734,
        2.734,
        2.688,
        2.688,
        2.641,
        2.578
      ],
      "average_max_activation": 1.56095,
      "min_max_activation": 2.578,
      "max_max_activation": 3.906
    },
    "prediction_evaluation_selection": {
      "total_exemplars": 42,
      "excluded_top_n": 10,
      "selected_count": 10,
      "selection_distribution": {
        "num_high": 4,
        "num_medium": 3,
        "num_low": 3
      },
      "selected_texts": [
        " queries that may return different results for different domains are",
        " googling descriptions and getting results. And I don't",
        " yielded inconsistent and inconclusive results. Thus, we conducted",
        " of the internet yielded no results. I think the issue",
        " Factorialize returns incorrect result\n\nJust wondering if anyone",
        "WE below yields the desired results. But, is there",
        "Q:\n\nQuery returns wrong result\n\nPossible Duplicate:\nWhy",
        " will inevitably generate very positive results in terms of turnover and",
        " best way to achieve expected result? As data array gets",
        " own calculations and returns a result, and I copy that"
      ],
      "selected_activations": [
        2.5,
        2.328,
        2.516,
        2.578,
        1.844,
        2.109,
        2.312,
        1.641,
        1.188,
        1.281
      ],
      "activation_range": [
        1.188,
        2.578
      ]
    },
    "note": "All activation evaluations use Neuronpedia API. Activation threshold is dynamically calculated from top 10 high-activating API exemplars (average of max activations / 2). Generation Evaluation uses top 10 high-activating exemplars. Prediction Evaluation uses selected exemplars directly from API (excluding top 10), with activation values already available (no API calls needed for activations). model_name and sae_path are kept for record-keeping only and are not used for any calculations."
  },
  "saia": {
    "explanation": {
      "description": "SAE Feature 10 (Layer 7) detects the outcome noun “result(s)” with strongest activation when it appears as the direct object of production/return/yield-style verbs (e.g., yield/produce/return), and shows near-zero activation for verb/idiom uses, near-synonyms, and many neutral/subject/reporting frames. Observed activations peak at 4.3438 on “results” and 4.2500 on “result”; moderate values appear in some return/produce contexts (1.859–3.781), while numerous neutral/reporting contexts are 0.000, indicating strong context dependence rather than uniform activation across all domains.",
      "evidence": "- Test 1: \"The search returned no results.\" → activation 2.7031 on 'results' (supports H1/H4)\n- Test 2: \"The search returned a result.\" → activation 3.0938 on 'result' (supports H2/H4)\n- Test 3: \"This may result in delays.\" → activation 0.0000 on 'result' (supports H3)\n- Test 4: \"The experiment yielded consistent results.\" → activation 4.3438 on 'results' (supports H1/H4)\n- Test 5: \"The outcomes were inconclusive.\" → activation 0.0000 on 'outcomes' (supports H5)\n- Test 6: \"The experiment produced a result.\" → activation 4.2500 on 'result' (supports H2/H4)\n- Test 7: \"The results are posted.\" → activation 0.0000 on 'results' (supports H4 boundary; refines H1)\n- Test 8: \"The findings were inconclusive.\" → activation 0.0000 on 'findings' (supports H5)\n- Test 9: \"Marketing produces results.\" → activation 1.8594 on 'results' (partial support H1/H4; lower magnitude)\n- Test 10: \"The algorithm returns results.\" → activation 3.7812 on 'results' (supports H1/H4)\n- Test 11: \"As a result, we left.\" → activation 0.0000 on 'result' (supports H3)\n- Test 12: \"Clinical trial results were promising.\" → activation 0.0000 on 'results' (contradicts broad H1; shows context specificity)\n- Test 13: \"Experimental results confirmed the theory.\" → activation 0.0000 on 'results' (contradicts broad H1; context specificity)\n- Test 14: \"We analyzed the results.\" → activation 0.0000 on 'results' (refines H1/H4: not all objects, only production/return-like)\n- Test 15: \"These results were published.\" → activation 0.0000 on 'results' (refines H1)\n- Test 16: \"No results were found.\" → activation 0.0000 on 'results' (refines H4 toward select verbs: return/yield/produce, not 'find')",
      "labels": [
        {
          "number": 1,
          "text": "Outcome noun “result(s)” in production/return/yield contexts (noun-only, wordform-specific; excludes verb/idiom and near-synonyms)"
        }
      ],
      "label1": "Outcome noun “result(s)” in production/return/yield contexts (noun-only, wordform-specific; excludes verb/idiom and near-synonyms)",
      "label2": ""
    },
    "generated_examples": [
      "The algorithm returns the result immediately after processing your input.",
      "Our experiments produced robust results across multiple datasets and conditions.",
      "This optimization yields better results with fewer iterations and less memory.",
      "The function will return a single result for each query.",
      "Their new process produced faster results than the old workflow.",
      "The model generated accurate results on previously unseen samples.",
      "This service delivers JSON results for every successful request.",
      "The trial yielded promising results without significant side effects.",
      "Our search query returned no results in the archive.",
      "That tweak produced exactly the result we needed."
    ],
    "generation_evaluation": {
      "metrics": {
        "total_examples": 10,
        "successful_examples": 9,
        "success_rate": 0.9,
        "avg_max_activation_all": 3.034375,
        "avg_mean_activation_all": 0.2696175244026807,
        "avg_max_activation_successful": 3.2447916666666665,
        "avg_mean_activation_successful": 0.288053562467625
      },
      "detailed_results": [
        {
          "example": "The algorithm returns the result immediately after processing your input.",
          "max_activation": 2.78125,
          "mean_activation": 0.23177083333333334,
          "success": true,
          "max_token": " result",
          "max_token_idx": 5,
          "tokens": [
            "<|im_end|>",
            "The",
            " algorithm",
            " returns",
            " the",
            " result",
            " immediately",
            " after",
            " processing",
            " your",
            " input",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            2.78125,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "Our experiments produced robust results across multiple datasets and conditions.",
          "max_activation": 4.21875,
          "mean_activation": 0.3515625,
          "success": true,
          "max_token": " results",
          "max_token_idx": 5,
          "tokens": [
            "<|im_end|>",
            "Our",
            " experiments",
            " produced",
            " robust",
            " results",
            " across",
            " multiple",
            " datasets",
            " and",
            " conditions",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            4.21875,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "This optimization yields better results with fewer iterations and less memory.",
          "max_activation": 3.40625,
          "mean_activation": 0.2620192307692308,
          "success": true,
          "max_token": " results",
          "max_token_idx": 5,
          "tokens": [
            "<|im_end|>",
            "This",
            " optimization",
            " yields",
            " better",
            " results",
            " with",
            " fewer",
            " iterations",
            " and",
            " less",
            " memory",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            3.40625,
            0,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "The function will return a single result for each query.",
          "max_activation": 3.5,
          "mean_activation": 0.3688151041666667,
          "success": true,
          "max_token": " result",
          "max_token_idx": 7,
          "tokens": [
            "<|im_end|>",
            "The",
            " function",
            " will",
            " return",
            " a",
            " single",
            " result",
            " for",
            " each",
            " query",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            3.5,
            0.92578125,
            0,
            0,
            0
          ]
        },
        {
          "example": "Their new process produced faster results than the old workflow.",
          "max_activation": 3.828125,
          "mean_activation": 0.3190104166666667,
          "success": true,
          "max_token": " results",
          "max_token_idx": 6,
          "tokens": [
            "<|im_end|>",
            "Their",
            " new",
            " process",
            " produced",
            " faster",
            " results",
            " than",
            " the",
            " old",
            " workflow",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            0,
            3.828125,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "The model generated accurate results on previously unseen samples.",
          "max_activation": 3.71875,
          "mean_activation": 0.33984375,
          "success": true,
          "max_token": " results",
          "max_token_idx": 5,
          "tokens": [
            "<|im_end|>",
            "The",
            " model",
            " generated",
            " accurate",
            " results",
            " on",
            " previously",
            " unseen",
            " samples",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            3.71875,
            0.01953125,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "This service delivers JSON results for every successful request.",
          "max_activation": 1.140625,
          "mean_activation": 0.10369318181818182,
          "success": false,
          "max_token": " results",
          "max_token_idx": 5,
          "tokens": [
            "<|im_end|>",
            "This",
            " service",
            " delivers",
            " JSON",
            " results",
            " for",
            " every",
            " successful",
            " request",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            1.140625,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "The trial yielded promising results without significant side effects.",
          "max_activation": 3.359375,
          "mean_activation": 0.3053977272727273,
          "success": true,
          "max_token": " results",
          "max_token_idx": 5,
          "tokens": [
            "<|im_end|>",
            "The",
            " trial",
            " yielded",
            " promising",
            " results",
            " without",
            " significant",
            " side",
            " effects",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            3.359375,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "Our search query returned no results in the archive.",
          "max_activation": 2.75,
          "mean_activation": 0.25,
          "success": true,
          "max_token": " results",
          "max_token_idx": 6,
          "tokens": [
            "<|im_end|>",
            "Our",
            " search",
            " query",
            " returned",
            " no",
            " results",
            " in",
            " the",
            " archive",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            0,
            2.75,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "That tweak produced exactly the result we needed.",
          "max_activation": 1.640625,
          "mean_activation": 0.1640625,
          "success": true,
          "max_token": " result",
          "max_token_idx": 6,
          "tokens": [
            "<|im_end|>",
            "That",
            " tweak",
            " produced",
            " exactly",
            " the",
            " result",
            " we",
            " needed",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            0,
            1.640625,
            0,
            0,
            0
          ]
        }
      ]
    },
    "prediction_evaluation": {
      "correlation": 0.44855191925901466,
      "p_value": 3.1211215505688206e-07,
      "predictions": [
        1.061815152917471e-06,
        7.744309554654492e-06,
        8.294524253232389e-06,
        6.083538631255662e-06,
        0.021567825074698628,
        0.0010759927231423756,
        4.664948577867701,
        1.0451147493465958,
        2.393433916221305,
        3.3810123601114856,
        0.7144281332712892,
        1.203500952523454e-06,
        2.667395600904933e-06,
        3.6117571536510196e-05,
        8.99335261644337e-05,
        4.12886368399651e-06,
        0.00011682084327051635,
        0.0020081684677157484,
        0.009505351533611702,
        1.5140448137899918e-05,
        2.0504213595193184e-05,
        0.0001749633736611456,
        0.0028106736187479627,
        1.6153424900506466e-06,
        3.4708253293663973,
        0.00014020657463324112,
        0.00020725635442777712,
        0.0746874091002426,
        0.0979418681647998,
        2.1305952439838514,
        4.030236188835774,
        1.4089811305593953,
        3.9605941320289646,
        0.0014970208737188017,
        0.02355921594402033,
        1.203500952523454e-06,
        5.137309453593287e-07,
        1.0441196355248801e-05,
        5.374923672502256e-06,
        0.0960332528254284,
        0.09271775676674082,
        4.254996310774701,
        4.260536035717692,
        0.013033033468968698,
        0.001068957041330429,
        0.36133321144421576,
        3.4152079958604986,
        1.3952179059597375e-06,
        1.6624002012960808e-05,
        0.00010668503949814693,
        0.0002421874279097062,
        0.7417123279447999,
        0.0037573350736893087,
        4.012757170830587,
        3.7399344944125787,
        0.7233348118666462,
        0.001080684001629633,
        9.289561710225743e-05,
        0.00021165081620479415,
        1.4727308885904264e-06,
        1.9044778769989728e-05,
        6.611262912789256e-05,
        1.7948025301143269,
        0.303419434342924,
        0.009082907053080864,
        4.347957700813811,
        4.590648705741176,
        4.222327139279714e-05,
        3.670571678888186,
        0.5439112575866427,
        0.7842321689606437,
        1.4814440083560114e-06,
        0.0001915669363961595,
        2.2377376639730522e-05,
        7.294406402470994e-05,
        1.8757018230716287,
        0.00027035844705842766,
        1.7171454889672613,
        2.8109459821409346,
        0.08731013475535584,
        0.5213455613428961,
        1.8842240569603466,
        0.000498728631771446,
        7.151028101973305e-07,
        8.32233413070605e-06,
        1.1173370027686881e-05,
        0.726968172891829,
        3.574802861096208e-05,
        0.00012960875808135173,
        4.532190653068689,
        0.009661448538609277,
        1.033288803909824,
        3.448480119332237,
        0.0018892478980329238,
        0.04987303737002867,
        2.612853031702776e-06,
        1.3562079411559955,
        3.0154377718249303e-05,
        1.6442231035123842,
        0.0016709005065165719,
        7.43802561215165e-05,
        0.000848527111534726,
        0.012102009910784518,
        0.00012011614765102005,
        2.212611617756083e-05,
        3.4535200788494996e-05,
        0.0016195825730807064,
        9.479409787980855e-07,
        2.3933038071193234e-05,
        0.00015702634824942623,
        3.009049821768371e-06,
        1.3087497398238186,
        0.0008166904513620686,
        3.7013667989840258,
        1.8370744122252671,
        0.06145021656954537,
        0.0021937493059918972,
        0.1414212726337038,
        0.011918715624251036
      ],
      "true_values": [
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        8.880568356374807,
        0.5700364823348694,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        9.760624679979518,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        1.190076164874552,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        8.760560675883257,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        6.280401945724527,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        9.92063492063492,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        9.520609318996415,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        7.40047363031234,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        7.800499231950845,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        7.640488991295442,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "num_tokens": 119,
      "num_examples": 10,
      "example_results": [
        {
          "text": " queries that may return different results for different domains are",
          "tokens": [
            "<|im_end|>",
            " queries",
            " that",
            " may",
            " return",
            " different",
            " results",
            " for",
            " different",
            " domains",
            " are"
          ],
          "predicted_values": [
            1.061815152917471e-06,
            7.744309554654492e-06,
            8.294524253232389e-06,
            6.083538631255662e-06,
            0.021567825074698628,
            0.0010759927231423756,
            4.664948577867701,
            1.0451147493465958,
            2.393433916221305,
            3.3810123601114856,
            0.7144281332712892
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            8.880568356374807,
            0.5700364823348694,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 11
        },
        {
          "text": " googling descriptions and getting results. And I don't",
          "tokens": [
            "<|im_end|>",
            " goog",
            "ling",
            " descriptions",
            " and",
            " getting",
            " results",
            ".",
            " And",
            " I",
            " don",
            "'t"
          ],
          "predicted_values": [
            1.203500952523454e-06,
            2.667395600904933e-06,
            3.6117571536510196e-05,
            8.99335261644337e-05,
            4.12886368399651e-06,
            0.00011682084327051635,
            0.0020081684677157484,
            0.009505351533611702,
            1.5140448137899918e-05,
            2.0504213595193184e-05,
            0.0001749633736611456,
            0.0028106736187479627
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            9.760624679979518,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": " yielded inconsistent and inconclusive results. Thus, we conducted",
          "tokens": [
            "<|im_end|>",
            " yielded",
            " inconsistent",
            " and",
            " incon",
            "clusive",
            " results",
            ".",
            " Thus",
            ",",
            " we",
            " conducted"
          ],
          "predicted_values": [
            1.6153424900506466e-06,
            3.4708253293663973,
            0.00014020657463324112,
            0.00020725635442777712,
            0.0746874091002426,
            0.0979418681647998,
            2.1305952439838514,
            4.030236188835774,
            1.4089811305593953,
            3.9605941320289646,
            0.0014970208737188017,
            0.02355921594402033
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.190076164874552,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": " of the internet yielded no results. I think the issue",
          "tokens": [
            "<|im_end|>",
            " of",
            " the",
            " internet",
            " yielded",
            " no",
            " results",
            ".",
            " I",
            " think",
            " the",
            " issue"
          ],
          "predicted_values": [
            1.203500952523454e-06,
            5.137309453593287e-07,
            1.0441196355248801e-05,
            5.374923672502256e-06,
            0.0960332528254284,
            0.09271775676674082,
            4.254996310774701,
            4.260536035717692,
            0.013033033468968698,
            0.001068957041330429,
            0.36133321144421576,
            3.4152079958604986
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            8.760560675883257,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": " Factorialize returns incorrect result\n\nJust wondering if anyone",
          "tokens": [
            "<|im_end|>",
            " Factor",
            "ial",
            "ize",
            " returns",
            " incorrect",
            " result",
            "\n\n",
            "Just",
            " wondering",
            " if",
            " anyone"
          ],
          "predicted_values": [
            1.3952179059597375e-06,
            1.6624002012960808e-05,
            0.00010668503949814693,
            0.0002421874279097062,
            0.7417123279447999,
            0.0037573350736893087,
            4.012757170830587,
            3.7399344944125787,
            0.7233348118666462,
            0.001080684001629633,
            9.289561710225743e-05,
            0.00021165081620479415
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            6.280401945724527,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": "WE below yields the desired results. But, is there",
          "tokens": [
            "<|im_end|>",
            "WE",
            " below",
            " yields",
            " the",
            " desired",
            " results",
            ".",
            " But",
            ",",
            " is",
            " there"
          ],
          "predicted_values": [
            1.4727308885904264e-06,
            1.9044778769989728e-05,
            6.611262912789256e-05,
            1.7948025301143269,
            0.303419434342924,
            0.009082907053080864,
            4.347957700813811,
            4.590648705741176,
            4.222327139279714e-05,
            3.670571678888186,
            0.5439112575866427,
            0.7842321689606437
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            9.92063492063492,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": "Q:\n\nQuery returns wrong result\n\nPossible Duplicate:\nWhy",
          "tokens": [
            "<|im_end|>",
            "Q",
            ":\n\n",
            "Query",
            " returns",
            " wrong",
            " result",
            "\n\n",
            "Possible",
            " Duplicate",
            ":\n",
            "Why"
          ],
          "predicted_values": [
            1.4814440083560114e-06,
            0.0001915669363961595,
            2.2377376639730522e-05,
            7.294406402470994e-05,
            1.8757018230716287,
            0.00027035844705842766,
            1.7171454889672613,
            2.8109459821409346,
            0.08731013475535584,
            0.5213455613428961,
            1.8842240569603466,
            0.000498728631771446
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            9.520609318996415,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": " will inevitably generate very positive results in terms of turnover and",
          "tokens": [
            "<|im_end|>",
            " will",
            " inevitably",
            " generate",
            " very",
            " positive",
            " results",
            " in",
            " terms",
            " of",
            " turnover",
            " and"
          ],
          "predicted_values": [
            7.151028101973305e-07,
            8.32233413070605e-06,
            1.1173370027686881e-05,
            0.726968172891829,
            3.574802861096208e-05,
            0.00012960875808135173,
            4.532190653068689,
            0.009661448538609277,
            1.033288803909824,
            3.448480119332237,
            0.0018892478980329238,
            0.04987303737002867
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            7.40047363031234,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": " best way to achieve expected result? As data array gets",
          "tokens": [
            "<|im_end|>",
            " best",
            " way",
            " to",
            " achieve",
            " expected",
            " result",
            "?",
            " As",
            " data",
            " array",
            " gets"
          ],
          "predicted_values": [
            2.612853031702776e-06,
            1.3562079411559955,
            3.0154377718249303e-05,
            1.6442231035123842,
            0.0016709005065165719,
            7.43802561215165e-05,
            0.000848527111534726,
            0.012102009910784518,
            0.00012011614765102005,
            2.212611617756083e-05,
            3.4535200788494996e-05,
            0.0016195825730807064
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            7.800499231950845,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": " own calculations and returns a result, and I copy that",
          "tokens": [
            "<|im_end|>",
            " own",
            " calculations",
            " and",
            " returns",
            " a",
            " result",
            ",",
            " and",
            " I",
            " copy",
            " that"
          ],
          "predicted_values": [
            9.479409787980855e-07,
            2.3933038071193234e-05,
            0.00015702634824942623,
            3.009049821768371e-06,
            1.3087497398238186,
            0.0008166904513620686,
            3.7013667989840258,
            1.8370744122252671,
            0.06145021656954537,
            0.0021937493059918972,
            0.1414212726337038,
            0.011918715624251036
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            7.640488991295442,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        }
      ],
      "skipped": false,
      "correlation_valid": true,
      "prediction_variance": 1.9269848310679984,
      "actual_variance": 5.078597515140776,
      "method": "logprobs_token_level",
      "token_usage": {
        "prompt_tokens": 26377,
        "completion_tokens": 119,
        "total_tokens": 26496,
        "cost_input": 0.03297125,
        "cost_output": 0.000595,
        "cost_total": 0.03356625
      },
      "activation_source": "neuronpedia_api",
      "api_config": {
        "model_id": "qwen3-4b",
        "layer": "7-transcoder-hp",
        "feature_index": 10
      }
    }
  },
  "neuronpedia": {
    "explanation": {
      "description": "mentions of outcomes or outputs, especially statements reporting or producing results",
      "label1": "",
      "label2": ""
    },
    "raw_api_response": {
      "explanation": {
        "id": "cmi3o339e0027pywnjadx5ie7",
        "modelId": "qwen3-4b",
        "layer": "7-transcoder-hp",
        "index": "10",
        "description": "mentions of outcomes or outputs, especially statements reporting or producing results",
        "authorId": "cmgfd4ew3004cnf0ds8gk5ogz",
        "triggeredByUserId": "cmgfd4ew3004cnf0ds8gk5ogz",
        "notes": null,
        "scoreV1": 0,
        "scoreV2": null,
        "umap_x": 0,
        "umap_y": 0,
        "umap_cluster": 0,
        "umap_log_feature_sparsity": 0,
        "typeName": "oai_token-act-pair",
        "explanationModelName": "gpt-5",
        "createdAt": "2025-11-17T21:39:05.666Z",
        "updatedAt": "2025-11-17T21:39:05.666Z"
      },
      "source": "new"
    },
    "explanation_source": "new",
    "explanation_id": "cmi3o339e0027pywnjadx5ie7",
    "all_available_explanations": [],
    "generated_examples": [
      "The experiment results show a 12% increase in battery life.",
      "The algorithm outputs 42 when given an empty input list.",
      "Final exam scores were posted; average result was seventy-eight percent.",
      "The biopsy returned negative results, confirming no malignancy.",
      "Our A/B test produced significantly higher conversions for variant B.",
      "Simulation output indicates a stable orbit over ten thousand iterations.",
      "The match outcome was a draw after extra time.",
      "Final tally shows 312 votes for, 289 against.",
      "The program prints Hello, world! and exits successfully.",
      "The lab report lists measured outputs: voltage, current, and resistance."
    ],
    "generation_evaluation": {
      "metrics": {
        "total_examples": 10,
        "successful_examples": 1,
        "success_rate": 0.1,
        "avg_max_activation_all": 0.2,
        "avg_mean_activation_all": 0.016666666666666666,
        "avg_max_activation_successful": 2.0,
        "avg_mean_activation_successful": 0.16666666666666666
      },
      "detailed_results": [
        {
          "example": "The experiment results show a 12% increase in battery life.",
          "max_activation": 0,
          "mean_activation": 0.0,
          "success": false,
          "max_token": "<|im_end|>",
          "max_token_idx": 0,
          "tokens": [
            "<|im_end|>",
            "The",
            " experiment",
            " results",
            " show",
            " a",
            " ",
            "1",
            "2",
            "%",
            " increase",
            " in",
            " battery",
            " life",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "The algorithm outputs 42 when given an empty input list.",
          "max_activation": 0,
          "mean_activation": 0.0,
          "success": false,
          "max_token": "<|im_end|>",
          "max_token_idx": 0,
          "tokens": [
            "<|im_end|>",
            "The",
            " algorithm",
            " outputs",
            " ",
            "4",
            "2",
            " when",
            " given",
            " an",
            " empty",
            " input",
            " list",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "Final exam scores were posted; average result was seventy-eight percent.",
          "max_activation": 0,
          "mean_activation": 0.0,
          "success": false,
          "max_token": "<|im_end|>",
          "max_token_idx": 0,
          "tokens": [
            "<|im_end|>",
            "Final",
            " exam",
            " scores",
            " were",
            " posted",
            ";",
            " average",
            " result",
            " was",
            " seventy",
            "-eight",
            " percent",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "The biopsy returned negative results, confirming no malignancy.",
          "max_activation": 2,
          "mean_activation": 0.16666666666666666,
          "success": true,
          "max_token": " results",
          "max_token_idx": 5,
          "tokens": [
            "<|im_end|>",
            "The",
            " biopsy",
            " returned",
            " negative",
            " results",
            ",",
            " confirming",
            " no",
            " malign",
            "ancy",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            2,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "Our A/B test produced significantly higher conversions for variant B.",
          "max_activation": 0,
          "mean_activation": 0.0,
          "success": false,
          "max_token": "<|im_end|>",
          "max_token_idx": 0,
          "tokens": [
            "<|im_end|>",
            "Our",
            " A",
            "/B",
            " test",
            " produced",
            " significantly",
            " higher",
            " conversions",
            " for",
            " variant",
            " B",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "Simulation output indicates a stable orbit over ten thousand iterations.",
          "max_activation": 0,
          "mean_activation": 0.0,
          "success": false,
          "max_token": "<|im_end|>",
          "max_token_idx": 0,
          "tokens": [
            "<|im_end|>",
            "Simulation",
            " output",
            " indicates",
            " a",
            " stable",
            " orbit",
            " over",
            " ten",
            " thousand",
            " iterations",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "The match outcome was a draw after extra time.",
          "max_activation": 0,
          "mean_activation": 0.0,
          "success": false,
          "max_token": "<|im_end|>",
          "max_token_idx": 0,
          "tokens": [
            "<|im_end|>",
            "The",
            " match",
            " outcome",
            " was",
            " a",
            " draw",
            " after",
            " extra",
            " time",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "Final tally shows 312 votes for, 289 against.",
          "max_activation": 0,
          "mean_activation": 0.0,
          "success": false,
          "max_token": "<|im_end|>",
          "max_token_idx": 0,
          "tokens": [
            "<|im_end|>",
            "Final",
            " tally",
            " shows",
            " ",
            "3",
            "1",
            "2",
            " votes",
            " for",
            ",",
            " ",
            "2",
            "8",
            "9",
            " against",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "The program prints Hello, world! and exits successfully.",
          "max_activation": 0,
          "mean_activation": 0.0,
          "success": false,
          "max_token": "<|im_end|>",
          "max_token_idx": 0,
          "tokens": [
            "<|im_end|>",
            "The",
            " program",
            " prints",
            " Hello",
            ",",
            " world",
            "!",
            " and",
            " exits",
            " successfully",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        },
        {
          "example": "The lab report lists measured outputs: voltage, current, and resistance.",
          "max_activation": 0,
          "mean_activation": 0.0,
          "success": false,
          "max_token": "<|im_end|>",
          "max_token_idx": 0,
          "tokens": [
            "<|im_end|>",
            "The",
            " lab",
            " report",
            " lists",
            " measured",
            " outputs",
            ":",
            " voltage",
            ",",
            " current",
            ",",
            " and",
            " resistance",
            "."
          ],
          "per_token_activations": [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
          ]
        }
      ]
    },
    "prediction_evaluation": {
      "correlation": 0.38106914200148556,
      "p_value": 1.9065044154595173e-05,
      "predictions": [
        1.0839470346985418,
        5.448300135361835,
        3.5507758869474983,
        3.8865949429395767,
        6.073580271669865,
        5.201980536037527,
        7.303241104106348,
        4.823148205720994,
        6.027428946684445,
        6.212327480901594,
        4.974854288069419,
        0.8275519159359292,
        4.593467099472894,
        5.221686006856678,
        5.6556064356915625,
        4.421181994207683,
        4.540788087197267,
        8.090065152042902,
        7.709141215671677,
        5.239229946761328,
        4.055644554680606,
        4.201298690875034,
        4.2166790684567355,
        1.0839470346985418,
        7.601379634623505,
        4.023931558451574,
        4.024256362325482,
        6.731870064923926,
        6.029500352902542,
        7.522969380873536,
        2.810860536107735,
        2.8937683741200524,
        3.9968008648432845,
        2.962255120971685,
        4.334522094235595,
        1.0839470346985418,
        2.8826235762235606,
        4.440523575008784,
        6.5298843112060005,
        5.700953484595837,
        3.5515165662853105,
        8.009967281451285,
        2.152866930360485,
        1.8123898589724952,
        3.720973183437552,
        3.387124893677387,
        3.484440019332795,
        2.019346267785824,
        5.027844586686248,
        4.299412784842151,
        5.751979906724895,
        5.9465527770097815,
        4.212397424554442,
        8.308430908926102,
        7.203697454697344,
        5.639114297533435,
        4.084835908625112,
        5.80713037882719,
        6.012208259929934,
        2.0240838215436074,
        3.2182964003878105,
        3.3891837295449303,
        6.9064399958835505,
        4.493478941164161,
        6.607368646904145,
        8.40508230660684,
        8.25358464601981,
        3.7316038963642213,
        7.025629015309135,
        6.11866009581776,
        5.544249143323611,
        1.3587303165954059,
        3.122617375853681,
        4.901773117838374,
        4.582369326290762,
        8.141759925013233,
        2.1136542533567995,
        8.110722410069409,
        6.9718001563640035,
        6.480728966929493,
        6.489221227326502,
        7.682181974510832,
        5.378310545285326,
        1.0839470346985418,
        4.867030490140698,
        7.261211521494734,
        7.826034483784398,
        6.365861832460903,
        8.335834381918888,
        8.82538492806462,
        8.325487138877968,
        8.276391270448732,
        8.187136662048431,
        8.469413257376539,
        7.9751129549768205,
        1.071852781932712,
        6.975489869525326,
        7.488542192152726,
        6.41749648454813,
        7.420200739079652,
        6.095116982317535,
        7.986452960560119,
        7.978336297511714,
        3.6112744951827254,
        5.499538243439259,
        5.9300298206204385,
        6.829396232468568,
        2.0240838215436074,
        4.279364734882869,
        5.708488743249184,
        3.4415238608591086,
        8.098961711110645,
        4.312575892982898,
        8.379644023542802,
        7.157991587512997,
        7.345400854674383,
        6.686173723875256,
        6.732617198818515,
        5.782633621987962
      ],
      "true_values": [
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        8.880568356374807,
        0.5700364823348694,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        9.760624679979518,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        1.190076164874552,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        8.760560675883257,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        6.280401945724527,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        9.92063492063492,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        9.520609318996415,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        7.40047363031234,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        7.800499231950845,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        7.640488991295442,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "num_tokens": 119,
      "num_examples": 10,
      "example_results": [
        {
          "text": " queries that may return different results for different domains are",
          "tokens": [
            "<|im_end|>",
            " queries",
            " that",
            " may",
            " return",
            " different",
            " results",
            " for",
            " different",
            " domains",
            " are"
          ],
          "predicted_values": [
            1.0839470346985418,
            5.448300135361835,
            3.5507758869474983,
            3.8865949429395767,
            6.073580271669865,
            5.201980536037527,
            7.303241104106348,
            4.823148205720994,
            6.027428946684445,
            6.212327480901594,
            4.974854288069419
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            8.880568356374807,
            0.5700364823348694,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 11
        },
        {
          "text": " googling descriptions and getting results. And I don't",
          "tokens": [
            "<|im_end|>",
            " goog",
            "ling",
            " descriptions",
            " and",
            " getting",
            " results",
            ".",
            " And",
            " I",
            " don",
            "'t"
          ],
          "predicted_values": [
            0.8275519159359292,
            4.593467099472894,
            5.221686006856678,
            5.6556064356915625,
            4.421181994207683,
            4.540788087197267,
            8.090065152042902,
            7.709141215671677,
            5.239229946761328,
            4.055644554680606,
            4.201298690875034,
            4.2166790684567355
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            9.760624679979518,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": " yielded inconsistent and inconclusive results. Thus, we conducted",
          "tokens": [
            "<|im_end|>",
            " yielded",
            " inconsistent",
            " and",
            " incon",
            "clusive",
            " results",
            ".",
            " Thus",
            ",",
            " we",
            " conducted"
          ],
          "predicted_values": [
            1.0839470346985418,
            7.601379634623505,
            4.023931558451574,
            4.024256362325482,
            6.731870064923926,
            6.029500352902542,
            7.522969380873536,
            2.810860536107735,
            2.8937683741200524,
            3.9968008648432845,
            2.962255120971685,
            4.334522094235595
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            1.190076164874552,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": " of the internet yielded no results. I think the issue",
          "tokens": [
            "<|im_end|>",
            " of",
            " the",
            " internet",
            " yielded",
            " no",
            " results",
            ".",
            " I",
            " think",
            " the",
            " issue"
          ],
          "predicted_values": [
            1.0839470346985418,
            2.8826235762235606,
            4.440523575008784,
            6.5298843112060005,
            5.700953484595837,
            3.5515165662853105,
            8.009967281451285,
            2.152866930360485,
            1.8123898589724952,
            3.720973183437552,
            3.387124893677387,
            3.484440019332795
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            8.760560675883257,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": " Factorialize returns incorrect result\n\nJust wondering if anyone",
          "tokens": [
            "<|im_end|>",
            " Factor",
            "ial",
            "ize",
            " returns",
            " incorrect",
            " result",
            "\n\n",
            "Just",
            " wondering",
            " if",
            " anyone"
          ],
          "predicted_values": [
            2.019346267785824,
            5.027844586686248,
            4.299412784842151,
            5.751979906724895,
            5.9465527770097815,
            4.212397424554442,
            8.308430908926102,
            7.203697454697344,
            5.639114297533435,
            4.084835908625112,
            5.80713037882719,
            6.012208259929934
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            6.280401945724527,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": "WE below yields the desired results. But, is there",
          "tokens": [
            "<|im_end|>",
            "WE",
            " below",
            " yields",
            " the",
            " desired",
            " results",
            ".",
            " But",
            ",",
            " is",
            " there"
          ],
          "predicted_values": [
            2.0240838215436074,
            3.2182964003878105,
            3.3891837295449303,
            6.9064399958835505,
            4.493478941164161,
            6.607368646904145,
            8.40508230660684,
            8.25358464601981,
            3.7316038963642213,
            7.025629015309135,
            6.11866009581776,
            5.544249143323611
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            9.92063492063492,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": "Q:\n\nQuery returns wrong result\n\nPossible Duplicate:\nWhy",
          "tokens": [
            "<|im_end|>",
            "Q",
            ":\n\n",
            "Query",
            " returns",
            " wrong",
            " result",
            "\n\n",
            "Possible",
            " Duplicate",
            ":\n",
            "Why"
          ],
          "predicted_values": [
            1.3587303165954059,
            3.122617375853681,
            4.901773117838374,
            4.582369326290762,
            8.141759925013233,
            2.1136542533567995,
            8.110722410069409,
            6.9718001563640035,
            6.480728966929493,
            6.489221227326502,
            7.682181974510832,
            5.378310545285326
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            9.520609318996415,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": " will inevitably generate very positive results in terms of turnover and",
          "tokens": [
            "<|im_end|>",
            " will",
            " inevitably",
            " generate",
            " very",
            " positive",
            " results",
            " in",
            " terms",
            " of",
            " turnover",
            " and"
          ],
          "predicted_values": [
            1.0839470346985418,
            4.867030490140698,
            7.261211521494734,
            7.826034483784398,
            6.365861832460903,
            8.335834381918888,
            8.82538492806462,
            8.325487138877968,
            8.276391270448732,
            8.187136662048431,
            8.469413257376539,
            7.9751129549768205
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            7.40047363031234,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": " best way to achieve expected result? As data array gets",
          "tokens": [
            "<|im_end|>",
            " best",
            " way",
            " to",
            " achieve",
            " expected",
            " result",
            "?",
            " As",
            " data",
            " array",
            " gets"
          ],
          "predicted_values": [
            1.071852781932712,
            6.975489869525326,
            7.488542192152726,
            6.41749648454813,
            7.420200739079652,
            6.095116982317535,
            7.986452960560119,
            7.978336297511714,
            3.6112744951827254,
            5.499538243439259,
            5.9300298206204385,
            6.829396232468568
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            7.800499231950845,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        },
        {
          "text": " own calculations and returns a result, and I copy that",
          "tokens": [
            "<|im_end|>",
            " own",
            " calculations",
            " and",
            " returns",
            " a",
            " result",
            ",",
            " and",
            " I",
            " copy",
            " that"
          ],
          "predicted_values": [
            2.0240838215436074,
            4.279364734882869,
            5.708488743249184,
            3.4415238608591086,
            8.098961711110645,
            4.312575892982898,
            8.379644023542802,
            7.157991587512997,
            7.345400854674383,
            6.686173723875256,
            6.732617198818515,
            5.782633621987962
          ],
          "actual_values": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            7.640488991295442,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "num_tokens": 12
        }
      ],
      "skipped": false,
      "correlation_valid": true,
      "prediction_variance": 4.346060378786043,
      "actual_variance": 5.078597515140776,
      "method": "logprobs_token_level",
      "token_usage": {
        "prompt_tokens": 11502,
        "completion_tokens": 119,
        "total_tokens": 11621,
        "cost_input": 0.0143775,
        "cost_output": 0.000595,
        "cost_total": 0.0149725
      },
      "activation_source": "neuronpedia_api",
      "api_config": {
        "model_id": "qwen3-4b",
        "layer": "7-transcoder-hp",
        "feature_index": 10
      }
    }
  },
  "prediction_evaluation": {
    "selected_exemplars": [
      {
        "text": " queries that may return different results for different domains are",
        "activation": 2.5
      },
      {
        "text": " googling descriptions and getting results. And I don't",
        "activation": 2.328
      },
      {
        "text": " yielded inconsistent and inconclusive results. Thus, we conducted",
        "activation": 2.516
      },
      {
        "text": " of the internet yielded no results. I think the issue",
        "activation": 2.578
      },
      {
        "text": " Factorialize returns incorrect result\n\nJust wondering if anyone",
        "activation": 1.844
      },
      {
        "text": "WE below yields the desired results. But, is there",
        "activation": 2.109
      },
      {
        "text": "Q:\n\nQuery returns wrong result\n\nPossible Duplicate:\nWhy",
        "activation": 2.312
      },
      {
        "text": " will inevitably generate very positive results in terms of turnover and",
        "activation": 1.641
      },
      {
        "text": " best way to achieve expected result? As data array gets",
        "activation": 1.188
      },
      {
        "text": " own calculations and returns a result, and I copy that",
        "activation": 1.281
      }
    ],
    "selection_method": "random_selection_from_categorized_exemplars",
    "selection_details": {
      "excluded_top_n": 10,
      "num_high_selected": 4,
      "num_medium_selected": 3,
      "num_low_selected": 3,
      "total_selected": 10
    },
    "note": "Prediction Evaluation uses selected exemplars directly from API (excluding top 10 used for Generation Evaluation). Exemplars are categorized into high, medium, and low activation groups from remaining exemplars, and randomly selected from each group. Activation values are already available from exemplars, so no API calls are needed to get activations. This avoids bias from explanation text and ensures diverse activation levels in evaluation examples."
  },
  "comparison": {
    "generation": {
      "saia": {
        "total_examples": 10,
        "successful_examples": 9,
        "success_rate": 0.9,
        "avg_max_activation_all": 3.034375,
        "avg_mean_activation_all": 0.2696175244026807,
        "avg_max_activation_successful": 3.2447916666666665,
        "avg_mean_activation_successful": 0.288053562467625
      },
      "neuronpedia": {
        "total_examples": 10,
        "successful_examples": 1,
        "success_rate": 0.1,
        "avg_max_activation_all": 0.2,
        "avg_mean_activation_all": 0.016666666666666666,
        "avg_max_activation_successful": 2.0,
        "avg_mean_activation_successful": 0.16666666666666666
      },
      "differences": {
        "success_rate_diff": 0.8,
        "avg_max_activation_diff": 2.8343749999999996,
        "avg_max_activation_successful_diff": 1.2447916666666665
      },
      "winner": "SAIA"
    },
    "prediction": {
      "saia": {
        "correlation": 0.44855191925901466,
        "p_value": 3.1211215505688206e-07,
        "correlation_valid": true
      },
      "neuronpedia": {
        "correlation": 0.38106914200148556,
        "p_value": 1.9065044154595173e-05,
        "correlation_valid": true
      },
      "difference": 0.0674827772575291,
      "winner": "TIE"
    },
    "overall_winner": "SAIA"
  }
}