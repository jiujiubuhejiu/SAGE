"""
Token Tracker - ç»Ÿè®¡LLMè°ƒç”¨çš„tokenä½¿ç”¨æƒ…å†µ
"""

from typing import Dict, Any, Optional
from dataclasses import dataclass, field
from datetime import datetime
import json


@dataclass
class TokenUsage:
    """å•æ¬¡APIè°ƒç”¨çš„tokenä½¿ç”¨"""
    model: str
    prompt_tokens: int = 0
    completion_tokens: int = 0
    cached_tokens: int = 0  # ç¼“å­˜çš„è¾“å…¥tokensï¼ˆå¦‚æœæ”¯æŒï¼‰
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    
    @property
    def total_tokens(self) -> int:
        """æ€»tokenæ•°ï¼ˆåŒ…æ‹¬ç¼“å­˜çš„ï¼‰"""
        return self.prompt_tokens + self.completion_tokens
    
    @property
    def non_cached_tokens(self) -> int:
        """éç¼“å­˜çš„tokenæ•°ï¼ˆç”¨äºè®¡è´¹ï¼‰"""
        return (self.prompt_tokens - self.cached_tokens) + self.completion_tokens
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "model": self.model,
            "prompt_tokens": self.prompt_tokens,
            "completion_tokens": self.completion_tokens,
            "cached_tokens": self.cached_tokens,
            "total_tokens": self.total_tokens,
            "non_cached_tokens": self.non_cached_tokens,
            "timestamp": self.timestamp
        }


class TokenTracker:
    """Tokenä½¿ç”¨ç»Ÿè®¡å™¨"""
    
    def __init__(self):
        self.usage_history: list[TokenUsage] = []
        self._model_prices: Dict[str, Dict[str, float]] = {
            "gpt-5": {
                "input": 0.625 / 1_000_000,  # $0.625 per 1M tokens
                "cached_input": 0.0625 / 1_000_000,  # $0.0625 per 1M tokens
                "output": 5.00 / 1_000_000  # $5.00 per 1M tokens
            },
            "gpt-5.1": {
                "input": 0.625 / 1_000_000,
                "cached_input": 0.0625 / 1_000_000,
                "output": 5.00 / 1_000_000
            },
            "gpt-5-nano": {
                "input": 0.625 / 1_000_000,  # å‡è®¾ä¸gpt-5ç›¸åŒ
                "cached_input": 0.0625 / 1_000_000,
                "output": 5.00 / 1_000_000
            },
            "gpt-5-mini": {
                "input": 0.625 / 1_000_000,  # å‡è®¾ä¸gpt-5ç›¸åŒ
                "cached_input": 0.0625 / 1_000_000,
                "output": 5.00 / 1_000_000
            },
            # å…¶ä»–æ¨¡å‹çš„é»˜è®¤ä»·æ ¼ï¼ˆå¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ ï¼‰
            "default": {
                "input": 0.625 / 1_000_000,
                "cached_input": 0.0625 / 1_000_000,
                "output": 5.00 / 1_000_000
            }
        }
    
    def record_usage(self, model: str, prompt_tokens: int = 0, 
                     completion_tokens: int = 0, cached_tokens: int = 0):
        """è®°å½•ä¸€æ¬¡tokenä½¿ç”¨"""
        usage = TokenUsage(
            model=model,
            prompt_tokens=prompt_tokens,
            completion_tokens=completion_tokens,
            cached_tokens=cached_tokens
        )
        self.usage_history.append(usage)
        return usage
    
    def get_model_price(self, model: str) -> Dict[str, float]:
        """è·å–æ¨¡å‹ä»·æ ¼é…ç½®"""
        # æ£€æŸ¥ç²¾ç¡®åŒ¹é…
        if model in self._model_prices:
            return self._model_prices[model]
        
        # æ£€æŸ¥å‰ç¼€åŒ¹é…ï¼ˆå¦‚ gpt-5-nano åŒ¹é… gpt-5ï¼‰
        for key, price in self._model_prices.items():
            if key != "default" and model.startswith(key):
                return price
        
        # è¿”å›é»˜è®¤ä»·æ ¼
        return self._model_prices["default"]
    
    def calculate_cost(self, usage: TokenUsage) -> float:
        """è®¡ç®—å•æ¬¡è°ƒç”¨çš„æˆæœ¬"""
        prices = self.get_model_price(usage.model)
        
        # éç¼“å­˜çš„è¾“å…¥tokens
        non_cached_input_tokens = usage.prompt_tokens - usage.cached_tokens
        input_cost = non_cached_input_tokens * prices["input"]
        
        # ç¼“å­˜çš„è¾“å…¥tokens
        cached_cost = usage.cached_tokens * prices["cached_input"]
        
        # è¾“å‡ºtokens
        output_cost = usage.completion_tokens * prices["output"]
        
        return input_cost + cached_cost + output_cost
    
    def get_summary(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡æ‘˜è¦"""
        if not self.usage_history:
            return {
                "total_calls": 0,
                "total_prompt_tokens": 0,
                "total_completion_tokens": 0,
                "total_cached_tokens": 0,
                "total_tokens": 0,
                "total_non_cached_tokens": 0,
                "total_cost_usd": 0.0,
                "by_model": {}
            }
        
        total_prompt = sum(u.prompt_tokens for u in self.usage_history)
        total_completion = sum(u.completion_tokens for u in self.usage_history)
        total_cached = sum(u.cached_tokens for u in self.usage_history)
        total_cost = sum(self.calculate_cost(u) for u in self.usage_history)
        
        # æŒ‰æ¨¡å‹åˆ†ç»„ç»Ÿè®¡
        by_model: Dict[str, Dict[str, Any]] = {}
        for usage in self.usage_history:
            if usage.model not in by_model:
                by_model[usage.model] = {
                    "calls": 0,
                    "prompt_tokens": 0,
                    "completion_tokens": 0,
                    "cached_tokens": 0,
                    "total_tokens": 0,
                    "non_cached_tokens": 0,
                    "cost_usd": 0.0
                }
            
            model_stats = by_model[usage.model]
            model_stats["calls"] += 1
            model_stats["prompt_tokens"] += usage.prompt_tokens
            model_stats["completion_tokens"] += usage.completion_tokens
            model_stats["cached_tokens"] += usage.cached_tokens
            model_stats["total_tokens"] += usage.total_tokens
            model_stats["non_cached_tokens"] += usage.non_cached_tokens
            model_stats["cost_usd"] += self.calculate_cost(usage)
        
        return {
            "total_calls": len(self.usage_history),
            "total_prompt_tokens": total_prompt,
            "total_completion_tokens": total_completion,
            "total_cached_tokens": total_cached,
            "total_tokens": total_prompt + total_completion,
            "total_non_cached_tokens": (total_prompt - total_cached) + total_completion,
            "total_cost_usd": total_cost,
            "by_model": by_model
        }
    
    def save_to_file(self, filepath: str):
        """ä¿å­˜ç»Ÿè®¡ç»“æœåˆ°æ–‡ä»¶"""
        summary = self.get_summary()
        detailed = {
            "summary": summary,
            "detailed_history": [u.to_dict() for u in self.usage_history]
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(detailed, f, indent=2, ensure_ascii=False)
    
    def print_summary(self):
        """æ‰“å°ç»Ÿè®¡æ‘˜è¦"""
        summary = self.get_summary()
        
        print("\n" + "="*60)
        print("ğŸ“Š Token Usage Summary")
        print("="*60)
        print(f"Total API Calls: {summary['total_calls']}")
        print(f"Total Tokens: {summary['total_tokens']:,}")
        print(f"  - Prompt Tokens: {summary['total_prompt_tokens']:,}")
        print(f"  - Completion Tokens: {summary['total_completion_tokens']:,}")
        print(f"  - Cached Tokens: {summary['total_cached_tokens']:,}")
        print(f"  - Non-cached Tokens: {summary['total_non_cached_tokens']:,}")
        print(f"Total Cost: ${summary['total_cost_usd']:.4f} USD")
        print("\nBy Model:")
        for model, stats in summary['by_model'].items():
            print(f"  {model}:")
            print(f"    Calls: {stats['calls']}")
            print(f"    Tokens: {stats['total_tokens']:,} (non-cached: {stats['non_cached_tokens']:,})")
            print(f"    Cost: ${stats['cost_usd']:.4f} USD")
        print("="*60 + "\n")


# å…¨å±€token trackerå®ä¾‹
_global_tracker: Optional[TokenTracker] = None


def get_tracker() -> TokenTracker:
    """è·å–å…¨å±€token trackerå®ä¾‹"""
    global _global_tracker
    if _global_tracker is None:
        _global_tracker = TokenTracker()
    return _global_tracker


def reset_tracker():
    """é‡ç½®å…¨å±€trackerï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
    global _global_tracker
    _global_tracker = None

